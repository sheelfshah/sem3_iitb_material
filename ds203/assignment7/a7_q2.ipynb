{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"haberman.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1  2  3\n",
       "0    30  64  1  1\n",
       "1    30  62  3  1\n",
       "2    30  65  0  1\n",
       "3    31  59  2  1\n",
       "4    31  65  4  1\n",
       "..   ..  .. .. ..\n",
       "301  75  62  1  1\n",
       "302  76  67  0  1\n",
       "303  77  65  3  1\n",
       "304  78  65  1  2\n",
       "305  83  58  2  2\n",
       "\n",
       "[306 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating Y\n",
    "df_y = df[3]\n",
    "df_y-=1\n",
    "# 0 if survived\n",
    "# 1 if not survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Y column\n",
    "df.drop([3], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size=0.8\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(df.to_numpy(), df_y.to_numpy(), train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit normalizer on training set and use it to transform test set\n",
    "normalizer = StandardScaler()  \n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[ 0.3934274  -0.09069496  0.59927071]]\n",
      "Intercept: [-1.06273887]\n"
     ]
    }
   ],
   "source": [
    "log_reg = lm.LogisticRegression()\n",
    "log_reg.fit(X_train_norm, y_train)\n",
    "print(\"Coefficients:\", log_reg.coef_)\n",
    "print(\"Intercept:\", log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test_norm)\n",
    "print(y_pred)\n",
    "# 0 if survived\n",
    "# 1 if not survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y_pred, y_actual):\n",
    "    error = y_pred!=y_actual\n",
    "    return np.sum(error)/len(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 0.24193548387096775\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Error:\", classification_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining into one function\n",
    "def train_log_reg(df, df_y, train_size):\n",
    "    X_train, X_test, y_train, y_test = ms.train_test_split(df.to_numpy(), df_y.to_numpy(), train_size=train_size)\n",
    "    normalizer = StandardScaler()  \n",
    "    X_train_norm = normalizer.fit_transform(X_train)\n",
    "    X_test_norm = normalizer.transform(X_test)\n",
    "    log_reg = lm.LogisticRegression()\n",
    "    log_reg.fit(X_train_norm, y_train)\n",
    "    y_pred = log_reg.predict(X_test_norm)\n",
    "    print(\"Classification Error:\", classification_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 0.20967741935483872\n"
     ]
    }
   ],
   "source": [
    "train_log_reg(df, df_y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 :\n",
      "Classification Error: 0.2682926829268293\n",
      "\n",
      "0.7 :\n",
      "Classification Error: 0.2608695652173913\n",
      "\n",
      "0.8 :\n",
      "Classification Error: 0.22580645161290322\n",
      "\n",
      "0.9 :\n",
      "Classification Error: 0.25806451612903225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sizes=[0.6, 0.7, 0.8, 0.9]\n",
    "for ts in train_sizes:\n",
    "    print(ts, \":\")\n",
    "    train_log_reg(df, df_y, train_size=ts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8 gives best performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv01",
   "language": "python",
   "name": "venv01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
